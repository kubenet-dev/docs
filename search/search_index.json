{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to <code>kubenet</code>, a community based approach to help network engineers better understand the potential of <code>kubernetes</code> for network automation. While we discuss networking, we are NOT talking about CNI(s) here, but about using <code>kubernetes</code> as an automation/orchestration engine to manage physical, virtual or containerized NOS(s).</p> <p>If you are interested to learn and discuss join us</p>"},{"location":"#why","title":"Why","text":"<p>Kubernetes stands out as the most extensive and robust automation and orchestration system available today. Originally focussed on container orchestration but leveraged across many industries, beyond container orchestration. The question to ask here is why is the networking industry not leveraging kubernetes for network automation. The Kubenet community is setup with to goal to help understand networking engineers the potential of kubernetes for network automation.</p> <p>Here are some attributes to consider why kubernetes is a good automation platform:</p> <ul> <li>Open Source: As an open-source platform, Kubernetes offers transparency, flexibility, and a collaborative community-driven approach. This fosters innovation and continuous improvement.</li> <li>Highly Extendable: Kubernetes is designed to be highly extendable, allowing for customization and integration with various tools and services to meet specific needs.</li> <li>Vast Ecosystem: The Kubernetes ecosystem is immense, with a wide range of tools, plugins, and extensions available. This ecosystem provides the resources needed to build comprehensive automation solutions.</li> <li>Declarative Model: Kubernetes uses a declarative model, making it easier to define and manage the desired state of network configurations.</li> <li>Event-Driven and Continuous Reconciliation: Kubernetes supports event-driven automation and continuous reconciliation, ensuring that the network\u2019s state is consistently aligned with the defined configurations.</li> <li>Collaborative Approach with GitOps: Leveraging GitOps principles, Kubernetes enables a collaborative approach to network management. Changes can be tracked, reviewed, and deployed using version control systems, enhancing transparency and collaboration.</li> <li>Extensive Knowledge Base: The widespread adoption of Kubernetes means there is a vast knowledge base and a large community of experts. This allows organizations to leverage existing expertise to extend and optimize their automation systems.</li> </ul>"},{"location":"#join-us","title":"Join us","text":"<p>Join us on this journey as we learn how to leverage kubernetes for network automation.</p> <p>Have questions, ideas, bug reports or just want to chat? Come join our discord server.</p>"},{"location":"01-getting-started/01_install/","title":"Getting Started","text":"<p>First check the prerequisites. Take special attention to the CPU and OS dependencies</p>"},{"location":"01-getting-started/01_install/#setup-environment","title":"Setup environment","text":"<p>The first step is setting up the environment:</p> <ul> <li>A kubernetes cluster (we use kind in the exercises)</li> <li>A network lab environment (we use containerlab in the exercises)</li> </ul> <p>Create a directory where the exercises will be executed. Some tools install files in this directory, so we dont want to mess with your environment.</p> <pre><code>mkdir -p kubenet; cd kubenet\n</code></pre> <p>Lets get started with setting up the environment. With the following command</p> <ul> <li>A kind kubernetes cluster is created</li> <li>An iprule is create to allow containerlab and the kind cluster to communicate</li> <li>A lab according to the following topology</li> </ul> clab topology <pre><code>name: topo3nodesrl\nmgmt:\nmtu: 1500\n#network: kind\nnetwork: kubenet  ipv4-subnet: 172.21.0.0/16\ntopology:\nkinds:\nnokia_srlinux:\nimage: ghcr.io/nokia/srlinux:24.3.2-118\nlinux:\nimage: ghcr.io/hellt/network-multitool\nnodes:\nedge01:\nkind: nokia_srlinux\ntype: ixrd2\nlabels:\nnetwork.infra.be.kuid.dev/device-type: edge ## can also be pe\nedge02:\nkind: nokia_srlinux\ntype: ixrd2\nlabels:\nnetwork.infra.be.kuid.dev/device-type: edge ## can also be pe\ncore01:\nkind: nokia_srlinux\ntype: ixrd3\nlabels:\nnetwork.infra.be.kuid.dev/device-type: core ## can also be p\nclient1:\nkind: linux\nlabels: infra.be.kuid.dev/exclude: \"true\"\nclient2:\nkind: linux\nlabels: infra.be.kuid.dev/exclude: \"true\"\nlinks:\n- endpoints: [\"edge01:e1-49\", \"core01:e1-1\"]\nlabels: infra.be.kuid.dev/link-type: infra\n- endpoints: [\"edge02:e1-49\", \"core01:e1-2\"]\nlabels: infra.be.kuid.dev/link-type: infra\n- endpoints: [\"client1:eth1\", \"edge01:e1-1\"]\nlabels: infra.be.kuid.dev/exclude: \"true\"\n- endpoints: [\"client2:eth1\", \"edge02:e1-1\"]\nlabels: infra.be.kuid.dev/exclude: \"true\"\n</code></pre> InteractiveAutomatic <p>kubenetctl has the option to run in interactive mode if you want to follow the steps one by one. If you are prompted with ..., hit ENTER</p> <pre><code>kubenetctl setup\n</code></pre> <p>When specifying the automatic option -a, kubenetctl will run the steps automatically one after the other</p> <pre><code>kubenetctl setup -a\n</code></pre> <p>A similar output is expected</p> <pre><code>Setup kubenet Environment\n=========================\n# create k8s kind cluster [1/3]:\n\n&gt; kind create cluster --name kubenet\nCreating cluster \"kubenet\" ...\n \u2713 Ensuring node image (kindest/node:v1.27.3) \ud83d\uddbc\n \u2713 Preparing nodes \ud83d\udce6  \n \u2713 Writing configuration \ud83d\udcdc \n \u2713 Starting control-plane \ud83d\udd79\ufe0f \n \u2713 Installing CNI \ud83d\udd0c \n \u2713 Installing StorageClass \ud83d\udcbe \nSet kubectl context to \"kind-kubenet\"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-kubenet\n\nThanks for using kind! \ud83d\ude0a\n\n# Allow the kind cluster to communicate with the containerlab topology (clab will be created in a later step) [2/3]:\n\n&gt; sudo iptables -I DOCKER-USER -o br-$(docker network inspect -f '{{ printf \"%.12s\" .ID }}' kind) -j ACCEPT\n\n# Deploy Containerlab topology [3/3]:\n\n&gt; sudo containerlab deploy -t https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/lab/3node.yaml --reconfigure\nINFO[0000] Containerlab v0.54.2 started                 \nINFO[0000] Parsing &amp; checking topology file: topo-3311532188.clab.yml \nINFO[0000] Removing /home/henderiw/test/kubenet/clab-topo3nodesrl directory... \nINFO[0000] Creating lab directory: /home/henderiw/test/kubenet/clab-topo3nodesrl \nINFO[0000] Creating container: \"client1\"                \nINFO[0000] Creating container: \"client2\"                \nINFO[0000] Creating container: \"core01\"                 \nINFO[0000] Creating container: \"edge01\"                 \nINFO[0000] Creating container: \"edge02\"                 \nINFO[0001] Created link: client1:eth1 &lt;--&gt; edge01:e1-1  \nINFO[0001] Running postdeploy actions for Nokia SR Linux 'edge01' node \nINFO[0001] Created link: client2:eth1 &lt;--&gt; edge02:e1-1  \nINFO[0001] Running postdeploy actions for Nokia SR Linux 'edge02' node \nINFO[0001] Created link: edge01:e1-49 &lt;--&gt; core01:e1-1  \nINFO[0001] Created link: edge02:e1-49 &lt;--&gt; core01:e1-2  \nINFO[0001] Running postdeploy actions for Nokia SR Linux 'core01' node \nINFO[0017] Adding containerlab host entries to /etc/hosts file \nINFO[0017] Adding ssh config for containerlab nodes     \n+---+---------------------------+--------------+---------------------------------+---------------+---------+---------------+--------------+\n| # |           Name            | Container ID |              Image              |     Kind      |  State  | IPv4 Address  | IPv6 Address |\n+---+---------------------------+--------------+---------------------------------+---------------+---------+---------------+--------------+\n| 1 | clab-topo3nodesrl-client1 | fe49acb930b9 | ghcr.io/hellt/network-multitool | linux         | running | 172.21.0.6/16 | N/A          |\n| 2 | clab-topo3nodesrl-client2 | dbb22872be06 | ghcr.io/hellt/network-multitool | linux         | running | 172.21.0.2/16 | N/A          |\n| 3 | clab-topo3nodesrl-core01  | 60447c1b38e6 | ghcr.io/nokia/srlinux           | nokia_srlinux | running | 172.21.0.3/16 | N/A          |\n| 4 | clab-topo3nodesrl-edge01  | 3ba50344c008 | ghcr.io/nokia/srlinux           | nokia_srlinux | running | 172.21.0.4/16 | N/A          |\n| 5 | clab-topo3nodesrl-edge02  | 320a373157a9 | ghcr.io/nokia/srlinux           | nokia_srlinux | running | 172.21.0.5/16 | N/A          |\n+---+---------------------------+--------------+---------------------------------+---------------+---------+---------------+--------------+\n</code></pre> <p>The following commands help to see the running containers. </p> <ul> <li>A container for the kind cluster</li> <li>3 srlinux containers (2 for the edge and 1 for the core)</li> <li>2 multitool test tools</li> </ul> <pre><code>docker ps\n</code></pre> <pre><code>CONTAINER ID   IMAGE                             COMMAND                  CREATED         STATUS         PORTS                       NAMES\n320a373157a9   ghcr.io/nokia/srlinux             \"/tini -- fixuid -q \u2026\"   2 minutes ago   Up 2 minutes                               clab-topo3nodesrl-edge02\n60447c1b38e6   ghcr.io/nokia/srlinux             \"/tini -- fixuid -q \u2026\"   2 minutes ago   Up 2 minutes                               clab-topo3nodesrl-core01\ndbb22872be06   ghcr.io/hellt/network-multitool   \"/docker-entrypoint.\u2026\"   2 minutes ago   Up 2 minutes   80/tcp, 443/tcp             clab-topo3nodesrl-client2\n3ba50344c008   ghcr.io/nokia/srlinux             \"/tini -- fixuid -q \u2026\"   2 minutes ago   Up 2 minutes                               clab-topo3nodesrl-edge01\nfe49acb930b9   ghcr.io/hellt/network-multitool   \"/docker-entrypoint.\u2026\"   2 minutes ago   Up 2 minutes   80/tcp, 443/tcp             clab-topo3nodesrl-client1\nf0fe7884d98d   kindest/node:v1.27.3              \"/usr/local/bin/entr\u2026\"   3 minutes ago   Up 3 minutes   127.0.0.1:43347-&gt;6443/tcp   kubenet-control-plane\n</code></pre> <p>\ud83c\udf89 Yeah \ud83c\udf89 you have a kubernetes cluster running. With the following command you can see the running pods. These are the base kubernetes building blocks</p> <pre><code>kubectl get pods -A\n</code></pre> <pre><code>NAMESPACE            NAME                                            READY   STATUS    RESTARTS   AGE\nkube-system          coredns-5d78c9869d-pm2nc                        1/1     Running   0          10m\nkube-system          coredns-5d78c9869d-t7jw6                        1/1     Running   0          10m\nkube-system          etcd-kubenet-control-plane                      1/1     Running   0          10m\nkube-system          kindnet-8g2cz                                   1/1     Running   0          10m\nkube-system          kube-apiserver-kubenet-control-plane            1/1     Running   0          10m\nkube-system          kube-controller-manager-kubenet-control-plane   1/1     Running   0          10m\nkube-system          kube-proxy-8bwmb                                1/1     Running   0          10m\nkube-system          kube-scheduler-kubenet-control-plane            1/1     Running   0          10m\nlocal-path-storage   local-path-provisioner-6bc4bddd6b-tjmt2         1/1     Running   0          10m\n</code></pre>"},{"location":"01-getting-started/01_install/#install-kubenet-components","title":"Install kubenet components","text":"<p>After the kind cluster is up and running, proceed to install the Kubenet components. These software building blocks are essential for the exercises and will help you interact with Kubernetes, providing insights into how Kubernetes can be leveraged for network automation use cases.</p> <ul> <li>pkgserver: A SW component that provides 2 way git access to kubernetes: basically read and write to a repository.</li> <li>sdc: A SW component that maps a kubernetes manifest to a YANG based system.</li> <li>kuid: An inventory and identity system, which allows to create resources and claim identifier required for networking (e.g. IPAM, VLAN, AS, etc). Some people think of this as a source of truth.</li> <li>kuidapps: Application leveraging the kuid backend API and extend kuid with applications that are tailored for specific tasks. E.g, a specific kuid app is installed to interact with Nokia SRLinux devices to translate the abstracted data-model of kuid to the specific implementation in SRLinux. Another app is setup to map the cointerlab topology into the kuid backend.</li> </ul> InteractiveAutomatic <p>kubenetctl has the option to run in interactive mode if you want to follow the steps one by one. If you are prompted with ..., hit ENTER</p> <pre><code>kubenetctl install\n</code></pre> <p>When specifying the automatic option -a, kubenetctl will run the steps automatically without human intervention</p> <pre><code>kubenetctl install -a\n</code></pre> <pre><code>Install kubenet Components\n==========================\n# install package server: (tool to interact with git from k8s using packages (KRM manifests)) [1/5]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/artifacts/out/pkgserver.yaml\nnamespace/pkg-system created\ncustomresourcedefinition.apiextensions.k8s.io/packagevariants.config.pkg.pkgserver.dev created\ncustomresourcedefinition.apiextensions.k8s.io/repositories.config.pkg.pkgserver.dev created\napiservice.apiregistration.k8s.io/v1alpha1.pkg.pkgserver.dev created\ndeployment.apps/pkg-server created\nclusterrole.rbac.authorization.k8s.io/pkg-server-clusterrole created\nclusterrolebinding.rbac.authorization.k8s.io/package:system:auth-delegator created\nclusterrolebinding.rbac.authorization.k8s.io/pkg-server-clusterrolebinding created\nrole.rbac.authorization.k8s.io/pkg-server-role created\nrolebinding.rbac.authorization.k8s.io/pkg-server-clusterrolebinding created\nrolebinding.rbac.authorization.k8s.io/pkg-server-auth-reader created\nsecret/pkg-server created\nservice/pkg-server created\nserviceaccount/pkg-server created\n\n# install sdc: (tool to interact with yang devices from k8s) [2/5]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/artifacts/out/sdc.yaml\nnamespace/network-system created\ncustomresourcedefinition.apiextensions.k8s.io/targetsyncprofiles.inv.sdcio.dev created\ncustomresourcedefinition.apiextensions.k8s.io/targetconnectionprofiles.inv.sdcio.dev created\ncustomresourcedefinition.apiextensions.k8s.io/schemas.inv.sdcio.dev created\ncustomresourcedefinition.apiextensions.k8s.io/discoveryrules.inv.sdcio.dev created\ncustomresourcedefinition.apiextensions.k8s.io/targets.inv.sdcio.dev created\napiservice.apiregistration.k8s.io/v1alpha1.config.sdcio.dev created\ndeployment.apps/config-server created\nclusterrole.rbac.authorization.k8s.io/config-server-clusterrole created\nclusterrolebinding.rbac.authorization.k8s.io/config-server-clusterrolebinding created\nclusterrolebinding.rbac.authorization.k8s.io/config:system:auth-delegator created\nrole.rbac.authorization.k8s.io/aggregated-apiserver-role created\nrolebinding.rbac.authorization.k8s.io/config-server-clusterrolebinding created\nrolebinding.rbac.authorization.k8s.io/config-auth-reader created\nconfigmap/data-server created\npersistentvolumeclaim/pvc-config-store created\npersistentvolumeclaim/pvc-schema-db created\npersistentvolumeclaim/pvc-schema-store created\nsecret/config-server-cert created\nservice/config-server created\nservice/data-server created\nserviceaccount/config-server created\n\n# install kuid-server: (tool for inventory and identity (IPAM/VLAN/AS/etc) using k8s api [3/5]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/artifacts/out/kuid-server.yaml\nnamespace/kuid-system created\napiservice.apiregistration.k8s.io/v1alpha1.as.be.kuid.dev created\napiservice.apiregistration.k8s.io/v1alpha1.extcomm.be.kuid.dev created\napiservice.apiregistration.k8s.io/v1alpha1.genid.be.kuid.dev created\napiservice.apiregistration.k8s.io/v1alpha1.infra.be.kuid.dev created\napiservice.apiregistration.k8s.io/v1alpha1.ipam.be.kuid.dev created\napiservice.apiregistration.k8s.io/v1alpha1.vlan.be.kuid.dev created\napiservice.apiregistration.k8s.io/v1alpha1.vxlan.be.kuid.dev created\ndeployment.apps/kuid-server created\nclusterrole.rbac.authorization.k8s.io/kuid-server-clusterrole created\nclusterrolebinding.rbac.authorization.k8s.io/kuid:system:auth-delegator created\nclusterrolebinding.rbac.authorization.k8s.io/kuid-server-clusterrolebinding created\nrole.rbac.authorization.k8s.io/kuid-server-apiserver-role created\nrolebinding.rbac.authorization.k8s.io/kuid-server-clusterrolebinding created\nrolebinding.rbac.authorization.k8s.io/kuid-server-auth-reader created\npersistentvolumeclaim/pvc-config-store created\nsecret/kuid-server created\nservice/kuid-server created\nserviceaccount/kuid-server created\n\n# install kuid-apps: (apps leveraging kuid-server focussed on networking [4/5]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/artifacts/out/kuidapps.yaml\ncustomresourcedefinition.apiextensions.k8s.io/networkconfigs.network.app.kuid.dev created\ncustomresourcedefinition.apiextensions.k8s.io/networkdevices.network.app.kuid.dev created\ncustomresourcedefinition.apiextensions.k8s.io/networks.network.app.kuid.dev created\ncustomresourcedefinition.apiextensions.k8s.io/topologies.topo.app.kuid.dev created\ndeployment.apps/kuidapps created\nclusterrole.rbac.authorization.k8s.io/kuidapps-clusterrole created\nclusterrolebinding.rbac.authorization.k8s.io/kuidapps-clusterrole-binding created\nrole.rbac.authorization.k8s.io/kuidapps-leader-election-role created\nrolebinding.rbac.authorization.k8s.io/kuidapps-leader-election-role-binding created\nserviceaccount/kuidapps created\n\n# install kuid-nokia-srl: (vendor specific app for specific nokia srl artifacts  [5/5]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/artifacts/out/kuid-nokia-srl.yaml\ncustomresourcedefinition.apiextensions.k8s.io/nodemodels.srl.nokia.app.kuid.dev created\ndeployment.apps/kuid-nokia-srl created\nclusterrole.rbac.authorization.k8s.io/kuid-nokia-srl-clusterrole created\nclusterrolebinding.rbac.authorization.k8s.io/kuid-nokia-srl-clusterrole-binding created\nrole.rbac.authorization.k8s.io/kuid-nokia-srl-leader-election-role created\nrolebinding.rbac.authorization.k8s.io/kuid-nokia-srl-leader-election-role-binding created\nconfigmap/gotemplates-srl created\nserviceaccount/kuid-nokia-srl created\n</code></pre> <pre><code>kubectl get pods -A\n</code></pre> <pre><code>NAMESPACE            NAME                                            READY   STATUS    RESTARTS   AGE\nkube-system          coredns-5d78c9869d-pm2nc                        1/1     Running   0          22m\nkube-system          coredns-5d78c9869d-t7jw6                        1/1     Running   0          22m\nkube-system          etcd-kubenet-control-plane                      1/1     Running   0          23m\nkube-system          kindnet-8g2cz                                   1/1     Running   0          22m\nkube-system          kube-apiserver-kubenet-control-plane            1/1     Running   0          23m\nkube-system          kube-controller-manager-kubenet-control-plane   1/1     Running   0          23m\nkube-system          kube-proxy-8bwmb                                1/1     Running   0          22m\nkube-system          kube-scheduler-kubenet-control-plane            1/1     Running   0          23m\nkuid-system          kuid-nokia-srl-68d7956db8-2c89h                 1/1     Running   0          11m\nkuid-system          kuid-server-74597d956b-rjkt6                    1/1     Running   0          11m\nkuid-system          kuidapps-5867fbfcbf-ztrn4                       1/1     Running   0          11m\nlocal-path-storage   local-path-provisioner-6bc4bddd6b-tjmt2         1/1     Running   0          22m\nnetwork-system       config-server-6ffb4bdcc8-wjnbw                  2/2     Running   0          11m\npkg-system           pkg-server-5444f74b69-px88b                     1/1     Running   0          11m\n</code></pre> <p>Hoera, the kubenet components are running. \ud83e\udd73</p> <p>Up to the next exercise discover devices. Lets discover to the srlinux devices, that were deployed by containerlab</p>"},{"location":"01-getting-started/02_prereq/","title":"Prerequisites","text":""},{"location":"01-getting-started/02_prereq/#cpu-architecture","title":"CPU architecture","text":"<p>All the kubernetes components run on both AMD and ARM based CPU, but most network OS(es) are not supported on ARM based CPU(s). As a result use an AMD based CPU to run the exercises.</p>"},{"location":"01-getting-started/02_prereq/#operating-system","title":"Operating system","text":"<p>We tested on WSL for windows and Linux and darwin OS.</p>"},{"location":"01-getting-started/02_prereq/#kubectl","title":"kubectl","text":"<p>Install kubectl</p>"},{"location":"01-getting-started/02_prereq/#auto-completions-for-kubectl-optional","title":"Auto completions for kubectl (optional)","text":"bashzsh <pre><code>source &lt;(kubectl completion bash)\nalias k=kubectl\ncomplete -o default -F __start_kubectl k\n</code></pre> <pre><code>source &lt;(kubectl completion zsh)\nalias k=kubectl\ncomplete -F _start_kubectl k\n</code></pre>"},{"location":"01-getting-started/02_prereq/#kubenetctl","title":"kubenetctl","text":"<p>kubenetctl is a single binary built for linux and Mac OS, distributed via ghreleases focussed to help run through the kubenet exercises. </p> <p>By default it runs in interactive mode, where you need to press enter between all steps. The -a option runs the step automatically while still printing what each step does</p> <p>The --shell option allows to change the shell used to execute the commands, by default it uses bash. If you wan to use another shell use --shell zsh e.g</p> linux/Mac OSPackages <p>To download &amp; install the latest release the following automated installation script can be used.</p> <pre><code>bash -c \"$(curl -sL https://github.com/kubenet-dev/kubenetctl/raw/main/install.sh)\"\n</code></pre> <p>As a result, the latest <code>kubenetctl</code> version will be installed in the /usr/local/bin directory and the version information will be printed out.</p> <p>To install a specific version of <code>kubenetctl</code>, provide the version with -v flag to the installation script:</p> <pre><code>bash -c \"$(curl -sL https://github.com/kubenet-dev/kubenetctl/raw/main/install.sh)\" -- -v 0.0.1\n</code></pre> <p>Linux users running distributions with support for deb/rpm packages can install gnmic using pre-built packages:</p> <pre><code>bash -c \"$(curl -sL https://github.com/kubenet-dev/kubenetctl/raw/main/install.sh)\" -- --use-pkg\n</code></pre>"},{"location":"01-getting-started/02_prereq/#install-kubernetes","title":"Install Kubernetes","text":"<p>we use kind for the exercises as it is a convenient tool to setup a kubernetes cluster </p> kindother <p>Install kind using kind</p> <p>In this example we install a <code>kind</code> cluster with name <code>sdc</code>. </p> <pre><code>kind create cluster --name sdc\n</code></pre>"},{"location":"02-examples/01_about/","title":"Examples","text":"<p>In this section we will run over various exercises leveraging kubernetes for network automation use case. There is a lot we unpack in these exercises. The following topics are covered in the various exercises.</p> <ul> <li>Device discovery</li> <li>Inventory management (Devices, Links, Endpoints/Interfaces)</li> <li>Identifier management (IPAM, VLAN, AS)</li> <li>Network Configuration and Automation</li> <li>Vendor Agnostic data modeling to Vendor specific data models with provider plugins</li> <li>Abstract network configuration</li> <li>Gitops workflows</li> <li>...</li> </ul> <p>Lets get started !</p> <p>The exercises use srlinux images, but we welcome other vendor to provide the mappings to their data/device models</p>"},{"location":"02-examples/02_discovery/","title":"Discovery","text":"<p>This exercise will focus on network device discovery. We will discover the deployed network devices that were deployed using containerlab in the installation section.</p> <p>Given sdc is build to support multiple vendors, the first thing we need to do is load the YANG schema for the respective vendor and release. In this exercise we use gNMI, but netconf could also be used.</p> Schema <pre><code>apiVersion: inv.sdcio.dev/v1alpha1\nkind: Schema\nmetadata:\nname: srl.nokia.sdcio.dev-24.3.2\nnamespace: default\nspec:\nrepoURL: https://github.com/sdcio/yang\nprovider: srl.nokia.sdcio.dev\nversion: 24.3.2\nkind: branch\nref: v24.3.2\ndirs:\n- src: .\ndst: .\nschema:\nmodels:\n- srl_nokia/models\nincludes:\n- ietf\n- openconfig/extensions\n- openconfig/openconfig-extensions.yang\nexcludes:\n- .*tools.*\n</code></pre> <p>After the schema is configured we create a set of profiles that sdc uses to connect and sync the configurations from the devices. Also the credentials, using secrets are setup for the respectve device.</p> Connection Profile <pre><code>apiVersion: inv.sdcio.dev/v1alpha1\nkind: TargetConnectionProfile\nmetadata:\nname: conn-gnmi-skipverify\nnamespace: default\nspec:\nport: 57400\nprotocol: gnmi\nencoding: ASCII\nskipVerify: true\ninsecure: false\n</code></pre> Sync Profile <pre><code>apiVersion: inv.sdcio.dev/v1alpha1\nkind: TargetSyncProfile\nmetadata:\nname: sync-gnmi-get\nnamespace: default\nspec:\nbuffer: 0\nworkers: 10\nvalidate: true\nsync:\n- name: config\nprotocol: gnmi\npaths:\n- /\nmode: get\ninterval: 30s\n</code></pre> <p>Lastly we configure a discovery rule that is used by sdc to discover the devices within the ip range we setup in the setup step.</p> Discovery rule <pre><code>apiVersion: inv.sdcio.dev/v1alpha1\nkind: DiscoveryRule\nmetadata:\nname: dr-dynamic\nnamespace: default\nspec:\nperiod: 1m\nconcurrentScans: 2\nprefixes:\n- prefix: 172.21.0.0/28\nexcludes:\n- 172.21.0.0\n- 172.21.0.1\n- 172.21.0.15\ndiscoveryProfile:\ncredentials: srl.nokia.sdcio.dev connectionProfiles:\n- conn-gnmi-skipverify\ntargetConnectionProfiles:\n- credentials: srl.nokia.sdcio.dev connectionProfile: conn-gnmi-skipverify\nsyncProfile: sync-gnmi-get\ntargetTemplate:\nlabels:\nsdcio.dev/region: us-east\n</code></pre> InteractiveAutomatic <p>kubenetctl has the option to run in interactive mode if you want to follow the steps one by one. If you are prompted with ..., hit ENTER</p> <pre><code>kubenetctl sdc\n</code></pre> <p>When specifying the automatic option -a, kubenetctl will run the steps automatically one after the other</p> <pre><code>kubenetctl sdc -a\n</code></pre> <pre><code>Configue sdc\n============\n# apply the schema for srlinux 24.3.2 [1/5]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/sdc/schemas/srl24-3-2.yaml\nschema.inv.sdcio.dev/srl.nokia.sdcio.dev-24.3.2 created\n\n# apply the gnmi profile to connect to the target (clab node) [2/5]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/sdc/profiles/conn-gnmi-skipverify.yaml\ntargetconnectionprofile.inv.sdcio.dev/conn-gnmi-skipverify created\n\n# apply the gnmi sync profile to sync config from the target (clab node) [3/5]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/sdc/profiles/sync-gnmi-get.yaml\ntargetsyncprofile.inv.sdcio.dev/sync-gnmi-get created\n\n# apply the srl secret with credentials to authenticate to the target (clab node) [4/5]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/sdc/profiles/secret.yaml\nsecret/srl.nokia.sdcio.dev created\n\n# apply the discovery rule to discover the srl devices deployed by containerlab [5/5]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/sdc/drrules/dr-dynamic.yaml\ndiscoveryrule.inv.sdcio.dev/dr-dynamic created\n</code></pre> <p>Lets see if this was successfull.</p> <pre><code> kubectl get targets\n</code></pre> <p>Wow \ud83c\udf89 we discovered the 3 devices setup with containerlab, with its respective MAC address, IP address, Provider, etc.</p> <pre><code>NAME     READY   REASON   PROVIDER              ADDRESS            PLATFORM      SERIALNUMBER     MACADDRESS\ncore01   True             srl.nokia.sdcio.dev   172.21.0.3:57400   7220 IXR-D3   Sim Serial No.   1A:D3:02:FF:00:00\nedge01   True             srl.nokia.sdcio.dev   172.21.0.4:57400   7220 IXR-D2   Sim Serial No.   1A:16:03:FF:00:00\nedge02   True             srl.nokia.sdcio.dev   172.21.0.5:57400   7220 IXR-D2   Sim Serial No.   1A:1D:04:FF:00:00\n</code></pre> <p>The following command allows to see the running config of the respective devices.</p> <pre><code>kubectl get runningconfigs.config.sdcio.dev core01 -o yaml\n</code></pre> <p>E.g. if you want to backup the config of your devices this command allows you to pull the configuration and back them up in your preferred backup system.</p> <p>Lets configure the network devices such that we can exchange routes and validate the configuration.</p>"},{"location":"02-examples/03_inventory/","title":"Inventory","text":"<p>In this exercise, we will focus on inventory and identifiers for network automation, commonly referred to as a source of truth. The goal is to demonstrate how we can leverage the extendability and flexibility of Kubernetes, which allows customization of the API and the development of applications that utilize this API to build various constructs for different use cases.</p> <p>Before configuring devices with IP, VLAN, BGP, and EVPN constructs, it is crucial to understand the topology these devices utilize. In this exercise, we have chosen to import the inventory used in the containerlab setup. This approach highlights how discovery and provisioning methods can be leveraged and interworked together.</p> <p>First, we create the device models for the srlinux devices used in our environment. This exercise demonstrates how to use a device profile for a specific role in the network and the corresponding device configuration. Different profiles can be applied for various network roles, with this configuration serving as the source of truth. It also shows how to handle a multi-vendor environment and customize configurations for different vendors and roles in the deployment.</p> <p>This capability is enabled using kuidapps, such as the Nokia-specific kuid app in this case. However, a specific vendor app can be installed for other vendors. In this exercise, we opted for a specific srlinux API (srl.nokia.app.kuid.dev/v1alpha1), but a vendor-agnostic API could also be used.</p> <p>We used this approach because containerlab will only connect and configure the interfaces used in the lab, but the automation might want to use other interfaces the device supports. You could also add specific information to each interface e.g. whether this interface is used for client/customer connectivity, etc</p> Specific vendor device model <pre><code>apiVersion: srl.nokia.app.kuid.dev/v1alpha1\nkind: NodeModel\nmetadata:\nname: ixrd2.srlinux.nokia.com\nnamespace: default\nspec:\nprovider: srlinux.nokia.com\ninterfaces:\n- name: \"e1-1\"\nspeed: \"25G\"\n- name: \"e1-2\"\nspeed: \"25G\"\n- name: \"e1-3\"\nspeed: \"25G\"\n- name: \"e1-4\"\nspeed: \"25G\"\n- name: \"e1-5\"\nspeed: \"25G\"\n- name: \"e1-6\"\nspeed: \"25G\"\n- name: \"e1-7\"\nspeed: \"25G\"\n- name: \"e1-8\"\nspeed: \"25G\"\n- name: \"e1-9\"\nspeed: \"25G\"\n- name: \"e1-10\"\nspeed: \"25G\"\n- name: \"e1-11\"\nspeed: \"25G\"\n- name: \"e1-12\"\nspeed: \"25G\"\n- name: \"e1-13\"\nspeed: \"25G\"\n- name: \"e1-14\"\nspeed: \"25G\"\n- name: \"e1-15\"\nspeed: \"25G\"\n- name: \"e1-16\"\nspeed: \"25G\"\n- name: \"e1-17\"\nspeed: \"25G\"\n- name: \"e1-18\"\nspeed: \"25G\"\n- name: \"e1-19\"\nspeed: \"25G\"\n- name: \"e1-20\"\nspeed: \"25G\"\n- name: \"e1-21\"\nspeed: \"25G\"\n- name: \"e1-22\"\nspeed: \"25G\"\n- name: \"e1-23\"\nspeed: \"25G\"\n- name: \"e1-24\"\nspeed: \"25G\"\n- name: \"e1-25\"\nspeed: \"25G\"\n- name: \"e1-26\"\nspeed: \"25G\"\n- name: \"e1-27\"\nspeed: \"25G\"\n- name: \"e1-28\"\nspeed: \"25G\"\n- name: \"e1-29\"\nspeed: \"25G\"\n- name: \"e1-30\"\nspeed: \"25G\"\n- name: \"e1-31\"\nspeed: \"25G\"\n- name: \"e1-32\"\nspeed: \"25G\"\n- name: \"e1-33\"\nspeed: \"25G\"\n- name: \"e1-34\"\nspeed: \"25G\"\n- name: \"e1-35\"\nspeed: \"25G\"\n- name: \"e1-36\"\nspeed: \"25G\"\n- name: \"e1-37\"\nspeed: \"25G\"\n- name: \"e1-38\"\nspeed: \"25G\"\n- name: \"e1-39\"\nspeed: \"25G\"\n- name: \"e1-40\"\nspeed: \"25G\"\n- name: \"e1-41\"\nspeed: \"25G\"\n- name: \"e1-42\"\nspeed: \"25G\"\n- name: \"e1-43\"\nspeed: \"25G\"\n- name: \"e1-44\"\nspeed: \"25G\"\n- name: \"e1-45\"\nspeed: \"25G\"\n- name: \"e1-46\"\nspeed: \"25G\"\n- name: \"e1-47\"\nspeed: \"25G\"\n- name: \"e1-48\"\nspeed: \"25G\"\n- name: \"e1-49\"\nspeed: \"100G\"\n- name: \"e1-50\"\nspeed: \"100G\"\n- name: \"e1-51\"\nspeed: \"100G\"\n- name: \"e1-52\"\nspeed: \"100G\"\n- name: \"e1-53\"\nspeed: \"100G\"\n- name: \"e1-54\"\nspeed: \"100G\"\n- name: \"e1-55\"\nspeed: \"100G\"\n- name: \"e1-56\"\nspeed: \"100G\"\napiVersion: srl.nokia.app.kuid.dev/v1alpha1\nkind: NodeModel\nmetadata:\nname: ixrd3.srlinux.nokia.com\nnamespace: default\nspec:\nprovider: srlinux.nokia.com\ninterfaces:\n- name: \"e1-1\"\nspeed: \"10G\"\n- name: \"e1-2\"\nspeed: \"10G\"\n- name: \"e1-3\"\nspeed: \"100G\"\n- name: \"e1-4\"\nspeed: \"100G\"\n- name: \"e1-5\"\nspeed: \"100G\"\n- name: \"e1-6\"\nspeed: \"100G\"\n- name: \"e1-7\"\nspeed: \"100G\"\n- name: \"e1-8\"\nspeed: \"100G\"\n- name: \"e1-9\"\nspeed: \"100G\"\n- name: \"e1-10\"\nspeed: \"100G\"\n- name: \"e1-11\"\nspeed: \"100G\"\n- name: \"e1-12\"\nspeed: \"100G\"\n- name: \"e1-13\"\nspeed: \"100G\"\n- name: \"e1-14\"\nspeed: \"100G\"\n- name: \"e1-15\"\nspeed: \"100G\"\n- name: \"e1-16\"\nspeed: \"100G\"\n- name: \"e1-17\"\nspeed: \"100G\"\n- name: \"e1-18\"\nspeed: \"100G\"\n- name: \"e1-19\"\nspeed: \"100G\"\n- name: \"e1-20\"\nspeed: \"100G\"\n- name: \"e1-21\"\nspeed: \"100G\"\n- name: \"e1-22\"\nspeed: \"100G\"\n- name: \"e1-23\"\nspeed: \"100G\"\n- name: \"e1-24\"\nspeed: \"100G\"\n- name: \"e1-25\"\nspeed: \"100G\"\n- name: \"e1-26\"\nspeed: \"100G\"\n- name: \"e1-27\"\nspeed: \"100G\"\n- name: \"e1-28\"\nspeed: \"100G\"\n- name: \"e1-29\"\nspeed: \"100G\"\n- name: \"e1-30\"\nspeed: \"100G\"\n- name: \"e1-31\"\nspeed: \"100G\"\n- name: \"e1-32\"\nspeed: \"100G\"\n- name: \"e1-33\"\nspeed: \"100G\"\n- name: \"e1-34\"\nspeed: \"100G\"\n</code></pre> <p>Afterwards you import the containerlab topology, which is used to populate the inventory in kuid.</p> Topology <pre><code>apiVersion: topo.app.kuid.dev/v1alpha1\nkind: Topology\nmetadata:\nname: topo3nodesrl\nspec:\nregion: region1\nsite: site1\ncontainerLab: |-\nname: topo3nodesrl\nmgmt:\nmtu: 1500\n#network: kind\nnetwork: kubenet  \nipv4-subnet: 172.21.0.0/16\ntopology:\nkinds:\nnokia_srlinux:\nimage: ghcr.io/nokia/srlinux\nlinux:\nimage: ghcr.io/hellt/network-multitool\nnodes:\nedge01:\nkind: nokia_srlinux\ntype: ixrd2\nlabels:\nnetwork.infra.be.kuid.dev/device-type: edge ## can also be pe\nedge02:\nkind: nokia_srlinux\ntype: ixrd2\nlabels:\nnetwork.infra.be.kuid.dev/device-type: edge ## can also be pe\ncore01:\nkind: nokia_srlinux\ntype: ixrd3\nlabels:\nnetwork.infra.be.kuid.dev/device-type: core ## can also be p\nclient1:\nkind: linux\nlabels: \ninfra.be.kuid.dev/exclude: \"true\"\nclient2:\nkind: linux\nlabels: \ninfra.be.kuid.dev/exclude: \"true\"\nlinks:\n- endpoints: [\"edge01:e1-49\", \"core01:e1-1\"]\nlabels: \ninfra.be.kuid.dev/link-type: infra\n- endpoints: [\"edge02:e1-49\", \"core01:e1-2\"]\nlabels: \ninfra.be.kuid.dev/link-type: infra\n- endpoints: [\"client1:eth1\", \"edge01:e1-1\"]\nlabels: \ninfra.be.kuid.dev/exclude: \"true\"\n- endpoints: [\"client2:eth1\", \"edge02:e1-1\"]\nlabels: \ninfra.be.kuid.dev/exclude: \"true\"\n</code></pre> <p>Execute the following command</p> InteractiveAutomatic <p>kubenetctl has the option to run in interactive mode if you want to follow the steps one by one. If you are prompted with ..., hit ENTER</p> <pre><code>kubenetctl inventory\n</code></pre> <p>When specifying the automatic option -a, kubenetctl will run the steps automatically one after the other</p> <pre><code>kubenetctl inventory -a\n</code></pre> <pre><code>Configue the topology inventory\n===============================\n# apply the nodemodel configuration for ixrd2 srlinux device [1/3]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/inventory/srl/ixrd2.yaml\nnodemodel.srl.nokia.app.kuid.dev/ixrd2.srlinux.nokia.com created\n\n# apply the nodemodel configuration for ixrd3 srlinux device [2/3]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/inventory/srl/ixrd3.yaml\nnodemodel.srl.nokia.app.kuid.dev/ixrd3.srlinux.nokia.com created\n\n# import the containerlab topology in kubernetes [3/3]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/topo/3node-topology.yaml\ntopology.topo.app.kuid.dev/topo3nodesrl created\n</code></pre> <p>Lets check the inventory in kuid.</p> <p>We first see that the 3 nodes are populated in the inventory system</p> <pre><code>kubectl get nodes.infra.be.kuid.dev \n</code></pre> <pre><code>NAME                                READY   REGION    SITE    TOPOLOGY       PROVIDER\ntopo3nodesrl.region1.site1.core01   True    region1   site1   topo3nodesrl   srlinux.nokia.com\ntopo3nodesrl.region1.site1.edge01   True    region1   site1   topo3nodesrl   srlinux.nokia.com\ntopo3nodesrl.region1.site1.edge02   True    region1   site1   topo3nodesrl   srlinux.nokia.com\n</code></pre> <p>We can also check the links.</p> <pre><code>kubectl get links.infra.be.kuid.dev \n</code></pre> <pre><code>NAME                                                                             READY   EPA                                       EPB\ntopo3nodesrl.region1.site1.edge01.e1-49.topo3nodesrl.region1.site1.core01.e1-1   True    topo3nodesrl.region1.site1.edge01.e1-49   topo3nodesrl.region1.site1.core01.e1-1\ntopo3nodesrl.region1.site1.edge02.e1-49.topo3nodesrl.region1.site1.core01.e1-2   True    topo3nodesrl.region1.site1.edge02.e1-49   topo3nodesrl.region1.site1.core01.e1-2\n</code></pre> <p>And Lastly the endpoints</p> <pre><code>kubectl get endpoints.infra.be.kuid.dev \n</code></pre> <p>Dont mind the False ready condition in the endpoint. No k8s controller is acting on this and hence the status is False</p> <pre><code>NAME                                      READY   TOPOLOGY       REGION    SITE    NODE\ntopo3nodesrl.region1.site1.core01.e1-1    False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-10   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-11   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-12   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-13   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-14   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-15   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-16   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-17   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-18   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-19   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-2    False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-20   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-21   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-22   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-23   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-24   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-25   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-26   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-27   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-28   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-29   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-3    False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-30   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-31   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-32   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-33   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-34   False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-4    False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-5    False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-6    False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-7    False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-8    False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.core01.e1-9    False   topo3nodesrl   region1   site1   core01\ntopo3nodesrl.region1.site1.edge01.e1-1    False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-10   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-11   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-12   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-13   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-14   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-15   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-16   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-17   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-18   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-19   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-2    False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-20   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-21   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-22   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-23   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-24   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-25   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-26   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-27   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-28   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-29   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-3    False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-30   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-31   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-32   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-33   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-34   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-35   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-36   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-37   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-38   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-39   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-4    False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-40   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-41   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-42   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-43   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-44   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-45   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-46   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-47   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-48   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-49   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-5    False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-50   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-51   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-52   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-53   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-54   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-55   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-56   False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-6    False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-7    False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-8    False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge01.e1-9    False   topo3nodesrl   region1   site1   edge01\ntopo3nodesrl.region1.site1.edge02.e1-1    False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-10   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-11   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-12   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-13   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-14   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-15   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-16   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-17   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-18   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-19   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-2    False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-20   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-21   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-22   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-23   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-24   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-25   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-26   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-27   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-28   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-29   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-3    False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-30   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-31   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-32   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-33   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-34   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-35   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-36   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-37   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-38   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-39   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-4    False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-40   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-41   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-42   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-43   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-44   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-45   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-46   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-47   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-48   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-49   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-5    False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-50   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-51   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-52   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-53   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-54   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-55   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-56   False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-6    False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-7    False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-8    False   topo3nodesrl   region1   site1   edge02\ntopo3nodesrl.region1.site1.edge02.e1-9    False   topo3nodesrl   region1   site1   edge02\n</code></pre> <p>We now have a full device and link inventory in the system, which we can use to build network constructs.</p>"},{"location":"02-examples/04_networkconfig/","title":"Network Config","text":"<p>Configuring networking involves managing numerous parameters and fine-tuning various settings. In this exercise, we demonstrate how to define network-wide parameters that network design engineers can use to accommodate diverse environments. The goal is to decouple the network design details from the service configuration. As such the detailed network design parameters are hidden from the people consuming the network. This is a technique to help abstraction.</p> <p>First, we create an IP Index, which acts like a routing table. This IP Index serves as the global network IP range for the entire setup. We configure both IPv4 and IPv6 prefixes to ensure comprehensive coverage and flexibility in addressing.</p> IP Index <pre><code>apiVersion: ipam.be.kuid.dev/v1alpha1\nkind: IPIndex\nmetadata:\nname: topo3nodesrl.default\nspec:\nprefixes:\n- prefix: 10.0.0.0/8\n- prefix: 1000::/32\n- prefix: 192.0.0.0/8\n- prefix: 1192::/32\n</code></pre> <p>The 2nd configuration defines various parameters for the network that are specific to network designers.</p> <ul> <li>Which IP prefix to be used for interfaces versus loopback IP(s)</li> <li>The selection of dual stack for addressing</li> <li>The use of EBGP for the underlay and the respective AS pool, for allocating AS numbers per device.</li> <li>The usage of a RR for IBGP</li> <li>The selection of EVPN for the overlay routes for L2 and L3</li> <li>Which encapsulation is used for overlays</li> <li>etc</li> </ul> <p>The parameters can be extended/tuned for other environments. The idea here is to show how one could use such a concept</p> <p>Below we can see which information we use in this exercise</p> Network config <pre><code>apiVersion: network.app.kuid.dev/v1alpha1\nkind: NetworkConfig\nmetadata:\nname: topo3nodesrl.default\nspec:\ntopology: topo3nodesrl\naddressing: dualstack\nprefixes:\n- prefix: 10.0.0.0/16\nlabels:\nipam.be.kuid.dev/ipprefix-type: pool # could be derived from purpose\ninfra.be.kuid.dev/purpose: loopback\n- prefix: 1000::/64\nlabels:\nipam.be.kuid.dev/ipprefix-type: pool # could be derived from purpose\ninfra.be.kuid.dev/purpose: loopback\n- prefix: 192.0.0.0/16\nlabels:\nipam.be.kuid.dev/ipprefix-type: network # could be derived from purpose\ninfra.be.kuid.dev/purpose: link-internal\n- prefix: 1192::/56\nlabels:\nipam.be.kuid.dev/ipprefix-type: network # could be derived from purpose\ninfra.be.kuid.dev/purpose: link-internal\nprotocols:\nibgp:\nas: 65535\nlocalAS: true\nrouteReflectors:\n- topo3nodesrl.default.core01.ipv4\nebgp: asPool: 65000-65100\nbgpEVPN: {}\nencapsulation: vxlan: {}\n</code></pre> <p>Execute the following command</p> interactiveautomatic <p>kubenetctl has the option to run in interactive mode if you want to follow the steps one by one. If you are prompted with ..., hit ENTER</p> <pre><code>kubenetctl networkconfig\n</code></pre> <p>When specifying the automatic option -a, kubenetctl will run the steps automatically one after the other</p> <pre><code>kubenetctl networkconfig -a\n</code></pre> <pre><code>Configue the default network configuration (config parameters for the underlay)\n===============================================================================\n# apply the ip index (network prefixes the network is setup with) [1/2]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/network/default-ipindex.yaml\nipindex.ipam.be.kuid.dev/topo3nodesrl.default created\n\n# apply the network config (network parameters for your network, BGP, VXLAN, Prefixes) [2/2]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/network/default-networkconfig.yaml\nnetworkconfig.network.app.kuid.dev/topo3nodesrl.default created\n</code></pre> <p>Lets see what happened</p> <p>An IP index is created with the respective IPs</p> <pre><code>kubectl get ipindices.ipam.be.kuid.dev \n</code></pre> <pre><code>NAME                   READY   PREFIX0      PREFIX1     PREFIX2       PREFIX3     PREFIX4\ntopo3nodesrl.default   True    10.0.0.0/8   1000::/32   192.0.0.0/8   1192::/32\n</code></pre> <p>A Set of IP claims are created for the respective loopbacks and inter-subnet links.</p> <pre><code>kubectl get ipclaims.ipam.be.kuid.dev \n</code></pre> <pre><code>NAME                                READY   INDEX                  CLAIMTYPE      PREFIXTYPE   CLAIMREQ       CLAIMRSP       DEFAULTGATEWAY\ntopo3nodesrl.default.10.0.0.0-16    True    topo3nodesrl.default   staticPrefix   pool         10.0.0.0/16    10.0.0.0/16    \ntopo3nodesrl.default.1000---64      True    topo3nodesrl.default   staticPrefix   pool         1000::/64      1000::/64      \ntopo3nodesrl.default.1192---56      True    topo3nodesrl.default   staticPrefix   network      1192::/56      1192::/56      \ntopo3nodesrl.default.192.0.0.0-16   True    topo3nodesrl.default   staticPrefix   network      192.0.0.0/16   192.0.0.0/16  \n</code></pre> <p>The AS pool is setup and we registered the AS number for the network</p> <pre><code>kubectl get asclaims.as.be.kuid.dev \n</code></pre> <pre><code>NAME                          READY   INDEX                  CLAIMTYPE   CLAIMREQ      CLAIMRSP\ntopo3nodesrl.default.aspool   True    topo3nodesrl.default   range       65000-65100   65000-65100\ntopo3nodesrl.default.ibgp     True    topo3nodesrl.default   staticID    65535         65535\n</code></pre> <p>All these parameters are registered through kuid API and can be leveraged as a source of truth that various components leverage for specific use cases. In the next examples you will see how certain networking applications leverage this for configuring the network,</p> <p>You are ready to configure underlay and overlay !!!.</p>"},{"location":"02-examples/05_defaultnetwork/","title":"Default Network","text":"<p>In this exercise we create the default network. The default network is your underlay network configuration, the network that interconnects all the devices. Looking at the configuration it looks really slim. The reason is that this leverages the parameters setup in the previous step network config.</p> Default Network <pre><code>apiVersion: network.app.kuid.dev/v1alpha1\nkind: Network\nmetadata:\nname: topo3nodesrl.default\nspec:\ntopology: topo3nodesrl\n</code></pre> <p>Execute the following command to instantiate the default network</p> InteractiveAutomatic <p>kubenetctl has the option to run in interactive mode if you want to follow the steps one by one. If you are prompted with ..., hit ENTER</p> <pre><code>kubenetctl networkdefault\n</code></pre> <p>When specifying the automatic option -a, kubenetctl will run the steps automatically one after the other</p> <pre><code>kubenetctl networkdefault -a\n</code></pre> <pre><code>Configue the default underlay network\n=====================================\n# apply the default network config [1/1]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/network/default-network.yaml\nnetwork.network.app.kuid.dev/topo3nodesrl.default created\n</code></pre> <p>While this looks really simple, a lot is happening under the hood. This default network is leveraging the network config setup in the previous step and allocates AS per device for the underlay, It allocate a IP prefix for each link in the network per address family and a IP address for its individual enpoints, etc. On top a device config is derived thorugh an abstract data model, which is mapped to srlinux for the specific implementation of the device. Once the device configuration is available for all the devices, the configurations are transacted to the device using sdc.</p> <p>!!!note \"In a later exercise (gitops) you will see that another option is to check in the resulting device configurations in git, rather than transacting to the network\".</p> <p>Lets go through some resources that got allocated through these steps.</p> <p>First an AS number per device is allocated, through the ASClaim API.</p> <pre><code>kubectl get asclaims.as.be.kuid.dev \n</code></pre> <pre><code>NAME                          READY   INDEX                  CLAIMTYPE   CLAIMREQ      CLAIMRSP\ntopo3nodesrl.default.aspool   True    topo3nodesrl.default   range       65000-65100   65000-65100\ntopo3nodesrl.default.core01   True    topo3nodesrl.default   dynamicID                 65002\ntopo3nodesrl.default.edge01   True    topo3nodesrl.default   dynamicID                 65001\ntopo3nodesrl.default.edge02   True    topo3nodesrl.default   dynamicID                 65000\ntopo3nodesrl.default.ibgp     True    topo3nodesrl.default   staticID    65535         65535\n</code></pre> <p>A Set of IP claims are created for the respective loopbacks and inter-subnet links using the IPClaim API.</p> <pre><code>kubectl get ipclaims.ipam.be.kuid.dev \n</code></pre> <pre><code>NAME                                                 READY   INDEX                  CLAIMTYPE        PREFIXTYPE   CLAIMREQ       CLAIMRSP                           DEFAULTGATEWAY\ntopo3nodesrl.default.10.0.0.0-16                     True    topo3nodesrl.default   staticPrefix     pool         10.0.0.0/16    10.0.0.0/16                        \ntopo3nodesrl.default.1000---64                       True    topo3nodesrl.default   staticPrefix     pool         1000::/64      1000::/64                          \ntopo3nodesrl.default.1192---56                       True    topo3nodesrl.default   staticPrefix     network      1192::/56      1192::/56                          \ntopo3nodesrl.default.192.0.0.0-16                    True    topo3nodesrl.default   staticPrefix     network      192.0.0.0/16   192.0.0.0/16                       \ntopo3nodesrl.default.core01.e1-1.ipv4                True    topo3nodesrl.default   dynamicAddress   network                     192.0.255.253/31                   \ntopo3nodesrl.default.core01.e1-1.ipv6                True    topo3nodesrl.default   dynamicAddress   network                     1192::2/127                        \ntopo3nodesrl.default.core01.e1-2.ipv4                True    topo3nodesrl.default   dynamicAddress   network                     192.0.0.3/31                       \ntopo3nodesrl.default.core01.e1-2.ipv6                True    topo3nodesrl.default   dynamicAddress   network                     1192::ff:ffff:ffff:ffff:fffd/127   \ntopo3nodesrl.default.core01.ipv4                     True    topo3nodesrl.default   dynamicAddress   pool                        10.0.0.0/32                        \ntopo3nodesrl.default.core01.ipv6                     True    topo3nodesrl.default   dynamicAddress   pool                        1000::2/128                        \ntopo3nodesrl.default.edge01.e1-49.core01.e1-1.ipv4   True    topo3nodesrl.default   dynamicPrefix    network                     192.0.255.252/31                   \ntopo3nodesrl.default.edge01.e1-49.core01.e1-1.ipv6   True    topo3nodesrl.default   dynamicPrefix    network                     1192::2/127                        \ntopo3nodesrl.default.edge01.e1-49.ipv4               True    topo3nodesrl.default   dynamicAddress   network                     192.0.255.252/31                   \ntopo3nodesrl.default.edge01.e1-49.ipv6               True    topo3nodesrl.default   dynamicAddress   network                     1192::3/127                        \ntopo3nodesrl.default.edge01.ipv4                     True    topo3nodesrl.default   dynamicAddress   pool                        10.0.0.1/32                        \ntopo3nodesrl.default.edge01.ipv6                     True    topo3nodesrl.default   dynamicAddress   pool                        1000::1/128                        \ntopo3nodesrl.default.edge02.e1-49.core01.e1-2.ipv4   True    topo3nodesrl.default   dynamicPrefix    network                     192.0.0.2/31                       \ntopo3nodesrl.default.edge02.e1-49.core01.e1-2.ipv6   True    topo3nodesrl.default   dynamicPrefix    network                     1192::ff:ffff:ffff:ffff:fffc/127   \ntopo3nodesrl.default.edge02.e1-49.ipv4               True    topo3nodesrl.default   dynamicAddress   network                     192.0.0.2/31                       \ntopo3nodesrl.default.edge02.e1-49.ipv6               True    topo3nodesrl.default   dynamicAddress   network                     1192::ff:ffff:ffff:ffff:fffc/127   \ntopo3nodesrl.default.edge02.ipv4                     True    topo3nodesrl.default   dynamicAddress   pool                        10.0.0.2/32                        \ntopo3nodesrl.default.edge02.ipv6                     True    topo3nodesrl.default   dynamicAddress   pool                        1000::/128    \n</code></pre> <p>The abstracted device models per device can be viewed with this command</p> <pre><code>kubectl get networkdevices.network.app.kuid.dev\n</code></pre> <pre><code>NAME                          READY   PROVIDER\ntopo3nodesrl.default.core01   True    srlinux.nokia.com\ntopo3nodesrl.default.edge01   True    srlinux.nokia.com\ntopo3nodesrl.default.edge02   True    srlinux.nokia.com\n</code></pre> <p>through the -o yaml option in <code>kubectl</code> you get the detailed view of the config in yaml format; -o json provide the json based output</p> <p>example command for the abstracted config of the edge01 device</p> <pre><code>kubectl get networkdevices.network.app.kuid.dev topo3nodesrl.default.edge01 -o yaml\n</code></pre> <p>The final device specific srlinux configuration send to the device can be seen through this command.</p> <pre><code>kubectl get configs.config.sdcio.dev \n</code></pre> <pre><code>NAME                          READY   REASON   TARGET           SCHEMA\ntopo3nodesrl.default.core01   True    ready    default/core01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.default.edge01   True    ready    default/edge01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.default.edge02   True    ready    default/edge02   srl.nokia.sdcio.dev/24.3.2\n</code></pre> <p>through the -o yaml option in <code>kubectl</code> you get the detailed view of the config in yaml format; -o json provide the json based output</p> <p>example command for the detailed srlinux config of the edge01 device</p> <pre><code>kubectl get configs.config.sdcio.dev  topo3nodesrl.default.edge01 -o yaml\n</code></pre> <p>Let's check if this finally ended up on the devices</p> edge01core01 <pre><code>docker exec clab-topo3nodesrl-edge01 sr_cli -- show network-instance summary\n</code></pre> <p>Expected output</p> <pre><code>+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n|             Name             |      Type      |  Admin state   |   Oper state   |          Router id           |             Description              |\n+==============================+================+================+================+==============================+======================================+\n| default                      | default        | enable         | up             |                              | k8s-default                          |\n| mgmt                         | ip-vrf         | enable         | up             |                              | Management network instance          |\n+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n</code></pre> <pre><code>docker exec clab-topo3nodesrl-edge01 sr_cli -- show network-instance default protocols bgp neighbor\n</code></pre> <p>Expected output</p> <pre><code>----------------------------------------------------------------------------------------------------------------------------------------------------------\nBGP neighbor summary for network-instance \"default\"\nFlags: S static, D dynamic, L discovered by LLDP, B BFD enabled, - disabled, * slow\n----------------------------------------------------------------------------------------------------------------------------------------------------------\n----------------------------------------------------------------------------------------------------------------------------------------------------------\n+-----------------+-------------------------+-----------------+------+---------+--------------+--------------+------------+-------------------------+\n|    Net-Inst     |          Peer           |      Group      | Flag | Peer-AS |    State     |    Uptime    |  AFI/SAFI  |     [Rx/Active/Tx]      |\n|                 |                         |                 |  s   |         |              |              |            |                         |\n+=================+=========================+=================+======+=========+==============+==============+============+=========================+\n| default         | 10.0.0.0                | overlay         | S    | 65535   | established  | 0d:0h:8m:2s  | evpn       | [0/0/0]                 |\n|                 |                         |                 |      |         |              |              | ipv4-      | [2/0/2]                 |\n|                 |                         |                 |      |         |              |              | unicast    | [2/0/2]                 |\n|                 |                         |                 |      |         |              |              | ipv6-      |                         |\n|                 |                         |                 |      |         |              |              | unicast    |                         |\n| default         | 192.0.255.253           | underlay        | S    | 65002   | established  | 0d:0h:8m:32s | ipv4-      | [2/2/1]                 |\n|                 |                         |                 |      |         |              |              | unicast    | [2/2/1]                 |\n|                 |                         |                 |      |         |              |              | ipv6-      |                         |\n|                 |                         |                 |      |         |              |              | unicast    |                         |\n| default         | 1192::2                 | underlay        | S    | 65002   | established  | 0d:0h:8m:37s | ipv4-      | [3/1/3]                 |\n|                 |                         |                 |      |         |              |              | unicast    | [3/2/3]                 |\n|                 |                         |                 |      |         |              |              | ipv6-      |                         |\n|                 |                         |                 |      |         |              |              | unicast    |                         |\n+-----------------+-------------------------+-----------------+------+---------+--------------+--------------+------------+-------------------------+\n----------------------------------------------------------------------------------------------------------------------------------------------------------\nSummary:\n3 configured neighbors, 3 configured sessions are established,0 disabled peers\n0 dynamic peers\n</code></pre> <pre><code>docker exec clab-topo3nodesrl-core01 sr_cli -- show network-instance summary\n</code></pre> <p>Expected output</p> <pre><code>+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n|             Name             |      Type      |  Admin state   |   Oper state   |          Router id           |             Description              |\n+==============================+================+================+================+==============================+======================================+\n| default                      | default        | enable         | up             |                              | k8s-default                          |\n| mgmt                         | ip-vrf         | enable         | up             |                              | Management network instance          |\n+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n</code></pre> <p>Expected output</p> <pre><code>docker exec clab-topo3nodesrl-core01 sr_cli -- show network-instance default protocols bgp neighbor\n</code></pre> <pre><code>----------------------------------------------------------------------------------------------------------------------------------------------------------\nBGP neighbor summary for network-instance \"default\"\nFlags: S static, D dynamic, L discovered by LLDP, B BFD enabled, - disabled, * slow\n----------------------------------------------------------------------------------------------------------------------------------------------------------\n----------------------------------------------------------------------------------------------------------------------------------------------------------\n+-----------------+-------------------------+-----------------+------+---------+--------------+--------------+------------+-------------------------+\n|    Net-Inst     |          Peer           |      Group      | Flag | Peer-AS |    State     |    Uptime    |  AFI/SAFI  |     [Rx/Active/Tx]      |\n|                 |                         |                 |  s   |         |              |              |            |                         |\n+=================+=========================+=================+======+=========+==============+==============+============+=========================+\n| default         | 10.0.0.1                | overlay         | S    | 65535   | established  | 0d:0h:9m:54s | evpn       | [0/0/0]                 |\n|                 |                         |                 |      |         |              |              | ipv4-      | [2/0/2]                 |\n|                 |                         |                 |      |         |              |              | unicast    | [2/0/2]                 |\n|                 |                         |                 |      |         |              |              | ipv6-      |                         |\n|                 |                         |                 |      |         |              |              | unicast    |                         |\n| default         | 10.0.0.2                | overlay         | S    | 65535   | established  | 0d:0h:9m:56s | evpn       | [0/0/0]                 |\n|                 |                         |                 |      |         |              |              | ipv4-      | [2/0/2]                 |\n|                 |                         |                 |      |         |              |              | unicast    | [2/0/2]                 |\n|                 |                         |                 |      |         |              |              | ipv6-      |                         |\n|                 |                         |                 |      |         |              |              | unicast    |                         |\n| default         | 192.0.0.2               | underlay        | S    | 65000   | established  | 0d:0h:10m:26 | ipv4-      | [1/1/2]                 |\n|                 |                         |                 |      |         |              | s            | unicast    | [1/1/2]                 |\n|                 |                         |                 |      |         |              |              | ipv6-      |                         |\n|                 |                         |                 |      |         |              |              | unicast    |                         |\n| default         | 192.0.255.252           | underlay        | S    | 65001   | established  | 0d:0h:10m:23 | ipv4-      | [1/1/2]                 |\n|                 |                         |                 |      |         |              | s            | unicast    | [1/1/2]                 |\n|                 |                         |                 |      |         |              |              | ipv6-      |                         |\n|                 |                         |                 |      |         |              |              | unicast    |                         |\n| default         | 1192::3                 | underlay        | S    | 65001   | established  | 0d:0h:10m:28 | ipv4-      | [3/0/3]                 |\n|                 |                         |                 |      |         |              | s            | unicast    | [3/1/3]                 |\n|                 |                         |                 |      |         |              |              | ipv6-      |                         |\n|                 |                         |                 |      |         |              |              | unicast    |                         |\n| default         | 1192::ff:ffff:ffff:ffff | underlay        | S    | 65000   | established  | 0d:0h:10m:31 | ipv4-      | [3/0/3]                 |\n|                 | :fffc                   |                 |      |         |              | s            | unicast    | [3/1/3]                 |\n|                 |                         |                 |      |         |              |              | ipv6-      |                         |\n|                 |                         |                 |      |         |              |              | unicast    |                         |\n+-----------------+-------------------------+-----------------+------+---------+--------------+--------------+------------+-------------------------+\n----------------------------------------------------------------------------------------------------------------------------------------------------------\nSummary:\n6 configured neighbors, 6 configured sessions are established,0 disabled peers\n0 dynamic peers\n</code></pre> <p>You can also see the resulting configuration using kubectl using the following command.</p> <pre><code>kubectl get runningconfigs.config.sdcio.dev core01 -o yaml\nkubectl get runningconfigs.config.sdcio.dev edge01 -o yaml\nkubectl get runningconfigs.config.sdcio.dev edge02 -o yaml\n</code></pre> <p>Lets see how we can do the same for overlays</p>"},{"location":"02-examples/06_bridgednetwork/","title":"Bridged Overlay Network","text":"<p>In this exercise we configure a bridged overlay network using EVPN. The same principle apply here. The default network config is used to simplify the configuration for the end user as much as possible.</p> Bridged Network <pre><code>apiVersion: network.app.kuid.dev/v1alpha1\nkind: Network\nmetadata:\nname: topo3nodesrl.vpc1\nspec:\ntopology: topo3nodesrl\nbridgeDomains:\n- name: br10\nnetworkID: 10\ninterfaces:\n- endpoint: e1-1\nnode: edge01\nregion: region1\nsite: site1\n- endpoint: e1-1\nnode: edge02\nregion: region1\nsite: site1\n</code></pre> <p>Execute the following command to instantiate the bridged network</p> InteractiveAutomatic <p>kubenetctl has the option to run in interactive mode if you want to follow the steps one by one. If you are prompted with ..., hit ENTER</p> <pre><code>kubenetctl networkbridged\n</code></pre> <p>When specifying the automatic option -a, kubenetctl will run the steps automatically one after the other</p> <pre><code>kubenetctl networkbridged -a\n</code></pre> <pre><code>Configue a bridged EVPN overlay network\n=======================================\n# apply the default network config [1/1]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/network/vpc1-bridged-network.yaml\nnetwork.network.app.kuid.dev/topo3nodesrl.vpc1 created\n</code></pre> <p>An abstract data model is derived per device for this confiuration, which is translated to the specific implementation of srlinux and finally transacted to the device. Important to note that only edge01 and edge02 got a new configuration, since these devices are only used for this specific configuration. The topology information is used to determine this.</p> <p>The abstracted device models per device can be viewed with this command</p> <pre><code>kubectl get networkdevices.network.app.kuid.dev\n</code></pre> <pre><code>NAME                          READY   PROVIDER\ntopo3nodesrl.default.core01   True    srlinux.nokia.com\ntopo3nodesrl.default.edge01   True    srlinux.nokia.com\ntopo3nodesrl.default.edge02   True    srlinux.nokia.com\ntopo3nodesrl.vpc1.edge01      True    srlinux.nokia.com\ntopo3nodesrl.vpc1.edge02      True    srlinux.nokia.com\n</code></pre> <p>through the -o yaml option in <code>kubectl</code> you get the detailed view of the config in yaml format; -o json provide the json based output</p> <p>example command for the abstracted config of the edge01 device</p> <pre><code>kubectl get networkdevices.network.app.kuid.dev topo3nodesrl.vpc1.edge01 -o yaml\n</code></pre> <p>The final device specific srlinux configuration send to the device can be seen through this command.</p> <pre><code>kubectl get configs.config.sdcio.dev \n</code></pre> <pre><code>NAME                          READY   REASON   TARGET           SCHEMA\ntopo3nodesrl.default.core01   True    ready    default/core01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.default.edge01   True    ready    default/edge01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.default.edge02   True    ready    default/edge02   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc1.edge01      True    ready    default/edge01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc1.edge02      True    ready    default/edge02   srl.nokia.sdcio.dev/24.3.2\n</code></pre> <p>through the -o yaml option in <code>kubectl</code> you get the detailed view of the config in yaml format; -o json provide the json based output</p> <p>example command for the detailed srlinux config of the edge01 device</p> <pre><code>kubectl get configs.config.sdcio.dev  topo3nodesrl.vpc1.edge01 -o yaml\n</code></pre> <p>Let's check if this final ended up on the devices.</p> edge01edge02 <pre><code>docker exec clab-topo3nodesrl-edge01 sr_cli -- show network-instance summary\n</code></pre> <p>Expected output</p> <pre><code>+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n|             Name             |      Type      |  Admin state   |   Oper state   |          Router id           |             Description              |\n+==============================+================+================+================+==============================+======================================+\n| default                      | default        | enable         | up             |                              | k8s-default                          |\n| mgmt                         | ip-vrf         | enable         | up             |                              | Management network instance          |\n| vpc1.br10                    | mac-vrf        | enable         | up             | N/A                          | k8s-vpc1.br10                        |\n+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n</code></pre> <pre><code>docker exec clab-topo3nodesrl-edge02 sr_cli -- show network-instance summary\n</code></pre> <p>Expected output</p> <pre><code>+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n|             Name             |      Type      |  Admin state   |   Oper state   |          Router id           |             Description              |\n+==============================+================+================+================+==============================+======================================+\n| default                      | default        | enable         | up             |                              | k8s-default                          |\n| mgmt                         | ip-vrf         | enable         | up             |                              | Management network instance          |\n| vpc1.br10                    | mac-vrf        | enable         | up             | N/A                          | k8s-vpc1.br10                        |\n+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n\n--{ + running }--[  ]--\n</code></pre> <p>You can also see the resulting configuration using kubectl using the following command.</p> <pre><code>kubectl get runningconfigs.config.sdcio.dev edge01 -o yaml\nkubectl get runningconfigs.config.sdcio.dev edge02 -o yaml\n</code></pre> <p>Nice !!</p>"},{"location":"02-examples/07_routednetwork/","title":"Routed Overlay Network","text":"<p>In this exercise we configure a routed overlay network using EVPN. The same principle apply here. The default network config is used to simplify the configuration for the end user as much as possible.</p> Routed Network <pre><code>apiVersion: network.app.kuid.dev/v1alpha1\nkind: Network\nmetadata:\nname: topo3nodesrl.vpc2\nspec:\ntopology: topo3nodesrl\nroutingTables:\n- name: rt20\nnetworkID: 20\ninterfaces:\n- endpoint: e1-1\nnode: edge01\nregion: region1\nsite: site1\naddresses:\n- address: 10.1.1.1/24\n- endpoint: e1-1\nnode: edge02\nregion: region1\nsite: site1\naddresses:\n- address: 10.2.2.1/24\n</code></pre> <p>Execute the following command to instantiate the routed network</p> InteractiveAutomatic <p>kubenetctl has the option to run in interactive mode if you want to follow the steps one by one. If you are prompted with ..., hit ENTER</p> <pre><code>kubenetctl networkrouted\n</code></pre> <p>When specifying the automatic option -a, kubenetctl will run the steps automatically one after the other</p> <pre><code>kubenetctl networkrouted -a\n</code></pre> <pre><code>Configue a routed overlay EVPN network\n======================================\n# apply the default network config [1/1]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/network/vpc2-routed-network.yaml\nnetwork.network.app.kuid.dev/topo3nodesrl.vpc2 created\n</code></pre> <p>An abstract data model is derived per device for this confiuration, which is translated to the specific implementation of srlinux and finally transacted to the device. Important to note that only edge01 and edge02 has a configuration, since these devices are only used for this specific configuration. The topology information is used to determine this.</p> <p>The abstracted device models per device can be viewed with this command</p> <pre><code>kubectl get networkdevices.network.app.kuid.dev\n</code></pre> <pre><code>NAME                          READY   PROVIDER\ntopo3nodesrl.default.core01   True    srlinux.nokia.com\ntopo3nodesrl.default.edge01   True    srlinux.nokia.com\ntopo3nodesrl.default.edge02   True    srlinux.nokia.com\ntopo3nodesrl.vpc1.edge01      True    srlinux.nokia.com\ntopo3nodesrl.vpc1.edge02      True    srlinux.nokia.com\ntopo3nodesrl.vpc2.edge01      True    srlinux.nokia.com\ntopo3nodesrl.vpc2.edge02      True    srlinux.nokia.com\n</code></pre> <p>through the -o yaml option in <code>kubectl</code> you get the detailed view of the config in yaml format; -o json provide the json based output</p> <p>example command for the abstracted config of the edge01 device</p> <pre><code>kubectl get networkdevices.network.app.kuid.dev topo3nodesrl.vpc2.edge01 -o yaml\n</code></pre> <p>The final device specific srlinux configuration send to the device can be seen through this command.</p> <pre><code>kubectl get configs.config.sdcio.dev \n</code></pre> <pre><code>NAME                          READY   REASON   TARGET           SCHEMA\ntopo3nodesrl.default.core01   True    ready    default/core01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.default.edge01   True    ready    default/edge01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.default.edge02   True    ready    default/edge02   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc1.edge01      True    ready    default/edge01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc1.edge02      True    ready    default/edge02   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc2.edge01      True    ready    default/edge01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc2.edge02      True    ready    default/edge02   srl.nokia.sdcio.dev/24.3.2\n</code></pre> <p>through the -o yaml option in <code>kubectl</code> you get the detailed view of the config in yaml format; -o json provide the json based output</p> <p>example command for the detailed srlinux config of the edge01 device</p> <pre><code>kubectl get configs.config.sdcio.dev  topo3nodesrl.vpc2.edge01 -o yaml\n</code></pre> <p>Let's check if this final ended up on the devices</p> edge01edge02 <pre><code>docker exec clab-topo3nodesrl-edge01 sr_cli -- show network-instance summary\n</code></pre> <p>Expected output</p> <pre><code>+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n|             Name             |      Type      |  Admin state   |   Oper state   |          Router id           |             Description              |\n+==============================+================+================+================+==============================+======================================+\n| default                      | default        | enable         | up             |                              | k8s-default                          |\n| mgmt                         | ip-vrf         | enable         | up             |                              | Management network instance          |\n| vpc1.br10                    | mac-vrf        | enable         | up             | N/A                          | k8s-vpc1.br10                        |\n| vpc2.rt20                    | ip-vrf         | enable         | up             |                              | k8s-vpc2.rt20                        |\n+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n</code></pre> <pre><code>docker exec clab-topo3nodesrl-edge02 sr_cli -- show network-instance summary\n</code></pre> <p>Expected output</p> <pre><code>+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n|             Name             |      Type      |  Admin state   |   Oper state   |          Router id           |             Description              |\n+==============================+================+================+================+==============================+======================================+\n| default                      | default        | enable         | up             |                              | k8s-default                          |\n| mgmt                         | ip-vrf         | enable         | up             |                              | Management network instance          |\n| vpc1.br10                    | mac-vrf        | enable         | up             | N/A                          | k8s-vpc1.br10                        |\n| vpc2.rt20                    | ip-vrf         | enable         | up             |                              | k8s-vpc2.rt20                        |\n+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n\n--{ + running }--[  ]--\n</code></pre> <p>You can also see the resulting configuration using kubectl using the following command.</p> <pre><code>kubectl get runningconfigs.config.sdcio.dev edge01 -o yaml\nkubectl get runningconfigs.config.sdcio.dev edge02 -o yaml\n</code></pre> <p>Nice, a single API for either routed or bridged, can we combine routed and bridged in the same network ? Yes we can see next exercise</p>"},{"location":"02-examples/08_irbnetwork/","title":"IRB Overlay Network","text":"<p>In this exercise we configure a irb overlay network using EVPN. The same principle apply here. The default network config is used to simplify the configuration for the end user as much as possible. Also note that the same API can be used to configure both routed and/or bridged instances.</p> IRB Network <pre><code>apiVersion: network.app.kuid.dev/v1alpha1\nkind: Network\nmetadata:\nname: topo3nodesrl.vpc3\nspec:\ntopology: topo3nodesrl\nbridgeDomains:\n- name: br30\nnetworkID: 30\ninterfaces:\n- endpoint: e1-1\nnode: edge01\nregion: region1\nsite: site1\n- endpoint: e1-1\nnode: edge02\nregion: region1\nsite: site1\nroutingTables:\n- name: rt35\nnetworkID: 35\ninterfaces:\n- bridgeDomain: br30\nnode: edge01\nregion: region1\nsite: site1\naddresses:\n- address: 10.0.1.1/24\n- bridgeDomain: br30\nnode: edge02\nregion: region1\nsite: site1\naddresses:\n- address: 10.0.2.1/24\n</code></pre> <p>Execute the following command to instantiate the routed network</p> InteractiveAutomatic <p>kubenetctl has the option to run in interactive mode if you want to follow the steps one by one. If you are prompted with ..., hit ENTER</p> <pre><code>kubenetctl networkirb\n</code></pre> <p>When specifying the automatic option -a, kubenetctl will run the steps automatically one after the other</p> <pre><code>kubenetctl networkirb -a\n</code></pre> <pre><code>Configue a IRB overlay EVPN network\n===================================\n# apply the default network config [1/1]:\n&gt; kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/v0.0.1/network/vpc3-irb-network.yaml\nnetwork.network.app.kuid.dev/topo3nodesrl.vpc3 created\n</code></pre> <p>An abstract data model is derived per device for this confiuration, which is translated to the specific implementation of srlinux and finally transacted to the device. Important to note that only Edge01 and edge01 has a configuration, since these devices are only used for this specific configuration. The topology information is used to determine this.</p> <p>The abstracted device models per device can be viewed with this command.</p> <pre><code>kubectl get networkdevices.network.app.kuid.dev\n</code></pre> <pre><code>AME                          READY   PROVIDER\ntopo3nodesrl.default.core01   True    srlinux.nokia.com\ntopo3nodesrl.default.edge01   True    srlinux.nokia.com\ntopo3nodesrl.default.edge02   True    srlinux.nokia.com\ntopo3nodesrl.vpc1.edge01      True    srlinux.nokia.com\ntopo3nodesrl.vpc1.edge02      True    srlinux.nokia.com\ntopo3nodesrl.vpc2.edge01      True    srlinux.nokia.com\ntopo3nodesrl.vpc2.edge02      True    srlinux.nokia.com\ntopo3nodesrl.vpc3.edge01      True    srlinux.nokia.com\ntopo3nodesrl.vpc3.edge02      True    srlinux.nokia.com\n</code></pre> <p>through the -o yaml option in <code>kubectl</code> you get the detailed view of the config in yaml format; -o json provide the json based output</p> <p>example command for the abstracted config of the edge01 device</p> <pre><code>kubectl get networkdevices.network.app.kuid.dev topo3nodesrl.vpc3.edge01 -o yaml\n</code></pre> <p>The final device specific srlinux configuration send to the device can be seen through this command.</p> <pre><code>kubectl get configs.config.sdcio.dev \n</code></pre> <pre><code>NAME                          READY   REASON   TARGET           SCHEMA\ntopo3nodesrl.default.core01   True    ready    default/core01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.default.edge01   True    ready    default/edge01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.default.edge02   True    ready    default/edge02   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc1.edge01      True    ready    default/edge01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc1.edge02      True    ready    default/edge02   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc2.edge01      True    ready    default/edge01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc2.edge02      True    ready    default/edge02   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc3.edge01      True    ready    default/edge01   srl.nokia.sdcio.dev/24.3.2\ntopo3nodesrl.vpc3.edge02      True    ready    default/edge02   srl.nokia.sdcio.dev/24.3.2\n</code></pre> <p>through the -o yaml option in <code>kubectl</code> you get the detailed view of the config in yaml format; -o json provide the json based output</p> <p>example command for the detailed srlinux config of the edge01 device</p> <pre><code>kubectl get configs.config.sdcio.dev  topo3nodesrl.vpc3.edge01 -o yaml\n</code></pre> <p>Let's check if this final ended up on the devices</p> edge01edge02 <pre><code>docker exec clab-topo3nodesrl-edge01 sr_cli -- show network-instance summary\n</code></pre> <p>Expected output</p> <pre><code>+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n|             Name             |      Type      |  Admin state   |   Oper state   |          Router id           |             Description              |\n+==============================+================+================+================+==============================+======================================+\n| default                      | default        | enable         | up             |                              | k8s-default                          |\n| mgmt                         | ip-vrf         | enable         | up             |                              | Management network instance          |\n| vpc1.br10                    | mac-vrf        | enable         | up             | N/A                          | k8s-vpc1.br10                        |\n| vpc2.rt20                    | ip-vrf         | enable         | up             |                              | k8s-vpc2.rt20                        |\n| vpc3.br30                    | mac-vrf        | enable         | up             | N/A                          | k8s-vpc3.br30                        |\n| vpc3.rt35                    | ip-vrf         | enable         | up             |                              | k8s-vpc3.rt35                        |\n+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n</code></pre> <pre><code>docker exec clab-topo3nodesrl-edge02 sr_cli -- show network-instance summary\n</code></pre> <p>Expected output</p> <pre><code>+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n|             Name             |      Type      |  Admin state   |   Oper state   |          Router id           |             Description              |\n+==============================+================+================+================+==============================+======================================+\n| default                      | default        | enable         | up             |                              | k8s-default                          |\n| mgmt                         | ip-vrf         | enable         | up             |                              | Management network instance          |\n| vpc1.br10                    | mac-vrf        | enable         | up             | N/A                          | k8s-vpc1.br10                        |\n| vpc2.rt20                    | ip-vrf         | enable         | up             |                              | k8s-vpc2.rt20                        |\n+------------------------------+----------------+----------------+----------------+------------------------------+--------------------------------------+\n\n--{ + running }--[  ]--\n</code></pre> <p>You can also see the resulting configuration using kubectl using the following command.</p> <pre><code>kubectl get runningconfigs.config.sdcio.dev edge01 -o yaml\nkubectl get runningconfigs.config.sdcio.dev edge02 -o yaml\n</code></pre> <p>Nice, a single API for both routed and/or bridged !! Lets explore gitops.</p>"},{"location":"02-examples/09_gitops/","title":"GitOps","text":"<p>So far we have seen that the device configurations that are derived from the network configs are directly transacted to the respective devices. However many people have expressed the need to validate and check the derived configurations before they can be applied to the network. This is where the package server comes in.</p> <p>The philiosphy in this exercise is like this. We have a set of catalog (templates) configuration people use to configure network constructs. Lets use the overlay's as an example. We have a system (git) in which these blueprints are maintained and we want to instantiate them to the network using the flow that we saw in the previous exercises. However there is 1 big difference, rather than transacting the specific device config directly, we want to check them in into git and someone ( a human or a ci system can validate them before they get applied to the network). If this workflow is relevant for you, this is an exercise you shoudl execute.</p> <p>First we register the repository in which the blueprints are maintained. This repo is public and uses a bridged network blueprint.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/main/pkg/repo/repo-catalog.yaml\n</code></pre> <p>After the repo is registered, the package server discovers the blueprint package from git. You can see the result using the following comman.</p> <pre><code>kubectl get packagerevisions.pkg.pkgserver.dev \n</code></pre> <p>We discovered the blueprint package and we can access it using the kubernetes API.</p> <pre><code>NAME                                     READY   REPOSITORY     TARGET    REALM     PACKAGE   REVISION   WORKSPACE   LIFECYCLE\ncatalog.repo-catalog.network.bridge.v1   True    repo-catalog   catalog   network   bridge    v1         v1          published\n</code></pre> <p>You could also look at the content, like this</p> <pre><code>kubectl describe packagerevisionresourceses.pkg.pkgserver.dev catalog.repo-catalog.network.bridge.v1 \n</code></pre> <pre><code>Name:         catalog.repo-catalog.network.bridge.v1\nNamespace:    default\nLabels:       &lt;none&gt;\nAnnotations:  pkg.pkgserver.dev/DiscoveredPkgRev: true\nAPI Version:  pkg.pkgserver.dev/v1alpha1\nKind:         PackageRevisionResources\nMetadata:\n  Creation Timestamp:  2024-05-26T19:00:26Z\n  Finalizers:\n    packagerevision.pkg.pkgserver.dev/finalizer\n    packagediscovery.pkg.pkgserver.dev/finalizer\n  Resource Version:  17693\n  UID:               a7d29fc6-80ef-4e84-9f7d-42bf7e3ea284\nSpec:\n  Package Rev ID:\n    Package:     bridge\n    Realm:       network\n    Repository:  repo-catalog\n    Revision:    v1\n    Target:      catalog\n    Workspace:   v1\n  Resources:\n    README.md:  # vpc1\n\nThis examples show a bridged network, which leverages the SRE parameters setup by the SRE on which parameters are used for your particular environemnt.\n\nit should be used with a topology setup using the identifiers specified.\n\ntopology: topo3nodesrl\nnodes: edge01, edge02\n    artifacts.yaml:  apiVersion: network.app.kuid.dev/v1alpha1\nkind: Network\nmetadata:\n  name: topo3nodesrl.vpc100\n  namespace: default\n  annotations:\n    kform.dev/block-type: resource\n    kform.dev/resource-type: kubernetes_manifest \n    kform.dev/resource-id: vpc100\nspec:\n  topology: topo3nodesrl\n  bridgeDomains:\n  - name: br100\n    networkID: 100\n    interfaces:\n    - endpoint: e1-1\n      node: edge01\n      region: region1\n      site: site1\n    - endpoint: e1-1\n      node: edge02\n      region: region1\n      site: site1\n\n---\napiVersion: kubernetes.provider.kform.dev/v1alpha1\nkind: ProviderConfig\nmetadata:\n  name: kubernetes\n  namespace: default\n  annotations:\n    kform.dev/block-type: provider\nStatus:\nEvents:  &lt;none&gt;\n</code></pre> <p>To continue with this exercise you should now setup your own repository, which is used to store the derived device specific configuration. We need to provide write access to the package server. As such you should setup 2 things.</p> <ol> <li>A git repository</li> <li>A token to access the git repository </li> </ol> <p>I am using my own git repo to show the exercise, but this repo should be replaced with your own. Here is some detail how this can be achieved.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/main/pkg/repo/repo-target.yaml\n</code></pre> <p>After this repo is registered the following show the respective information</p> <pre><code>kubectl get repositories.config.pkg.pkgserver.dev\n</code></pre> <pre><code>NAME           READY   DEPLOYMENT   TYPE   ADDRESS\nrepo-catalog   True                 git    https://github.com/kubenet-dev/examples.git\nrepo-target    True    true         git    https://github.com/kubenet-dev/demo.git\n</code></pre> <p>Once this is configured, lets install the blueprint. This can be done using the package variant resource/API.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubenet-dev/kubenet/main/pkg/pvar/pvar-bridge.yaml\n</code></pre> <p>A packagevariant is a way to instantiate a variant of the package revision. The package variant has an upstream reference (blueprint) and a downstream reference (the repo in which the final device configurations will be stored). On top you could also supply input variant information to customize the specific parameters for the environment. We dont use this in this excersize, but no we hope you understand where the name is coming from (Creating a variant of a blueprint package with specific parameters).</p> <p>Once the package variant is instantiated a new package revision is created in the downstream repo (the repo you created) with LifecycleStatus = Draft.</p> <pre><code>kubectl get packagerevisions.pkg.pkgserver.dev \n</code></pre> <pre><code>NAME                                                          READY   REPOSITORY     TARGET         REALM     PACKAGE   REVISION   WORKSPACE             LIFECYCLE\ncatalog.repo-catalog.network.bridge.v1                        True    repo-catalog   catalog        network   bridge    v1         v1                    published\ntopo3nodesrl.repo-target.network.bridge.pv-077eb8d077b36655   True    repo-target    topo3nodesrl   network   bridge               pv-077eb8d077b36655   draft\n</code></pre> <p>Once the pipeline completes you should see the resulting configuration in the package revision with the final device configuration derived from the blueprint content you instantiated through the package variant.</p> <pre><code>kubectl describe packagerevisionresourceses.pkg.pkgserver.dev topo3nodesrl.repo-target.network.bridge.pv-077eb8d077b36655 \n</code></pre> <pre><code>Name:         topo3nodesrl.repo-target.network.bridge.pv-077eb8d077b36655\nNamespace:    default\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nAPI Version:  pkg.pkgserver.dev/v1alpha1\nKind:         PackageRevisionResources\nMetadata:\n  Creation Timestamp:  2024-05-26T19:05:26Z\n  Finalizers:\n    packagerevision.pkg.pkgserver.dev/finalizer\n    networkpackage.network.app.kuid.dev/finalizer\n  Owner References:\n    API Version:     config.pkg.pkgserver.dev/v1alpha1\n    Controller:      true\n    Kind:            PackageVariant\n    Name:            pv-network-bridge\n    UID:             90656874-0bab-44c9-b5e5-51f36120f053\n  Resource Version:  18474\n  UID:               ca87d87b-e468-4358-abbd-87719fe2b9d5\nSpec:\n  Package Rev ID:\n    Package:     bridge\n    Realm:       network\n    Repository:  repo-target\n    Target:      topo3nodesrl\n    Workspace:   pv-077eb8d077b36655\n  Resources:\n    README.md:  # vpc1\n\nThis examples show a bridged network, which leverages the SRE parameters setup by the SRE on which parameters are used for your particular environemnt.\n\nit should be used with a topology setup using the identifiers specified.\n\ntopology: topo3nodesrl\nnodes: edge01, edge02\n    artifacts.yaml:  apiVersion: network.app.kuid.dev/v1alpha1\nkind: Network\nmetadata:\n  name: topo3nodesrl.vpc100\n  namespace: default\n  annotations:\n    kform.dev/block-type: resource\n    kform.dev/resource-type: kubernetes_manifest \n    kform.dev/resource-id: vpc100\nspec:\n  topology: topo3nodesrl\n  bridgeDomains:\n  - name: br100\n    networkID: 100\n    interfaces:\n    - endpoint: e1-1\n      node: edge01\n      region: region1\n      site: site1\n    - endpoint: e1-1\n      node: edge02\n      region: region1\n      site: site1\n\n---\napiVersion: kubernetes.provider.kform.dev/v1alpha1\nkind: ProviderConfig\nmetadata:\n  name: kubernetes\n  namespace: default\n  annotations:\n    kform.dev/block-type: provider\n    out/config.sdcio.dev_v1alpha1.Config.default.topo3nodesrl.vpc100.edge01.yaml:  apiVersion: config.sdcio.dev/v1alpha1\nkind: Config\nmetadata:\n  creationTimestamp: null\n  labels:\n    config.sdcio.dev/targetName: edge01\n    config.sdcio.dev/targetNamespace: default\n  name: topo3nodesrl.vpc100.edge01\n  namespace: default\nspec:\n  config:\n  - path: /\n    value:\n      interface:\n      - admin-state: enable\n        description: k8s-ethernet-1/1\n        ethernet: {}\n        name: ethernet-1/1\n        subinterface:\n        - admin-state: enable\n          description: k8s-customer\n          index: 100\n          type: bridged\n          vlan:\n            encap:\n              single-tagged:\n                vlan-id: 100\n        vlan-tagging: true\n      network-instance:\n      - admin-state: enable\n        description: k8s-vpc100.br100\n        interface:\n        - name: ethernet-1/1.100\n        name: vpc100.br100\n        protocols:\n          bgp-evpn:\n            bgp-instance:\n            - admin-state: enable\n              encapsulation-type: vxlan\n              evi: 100\n              id: 1\n              vxlan-interface: vxlan0.100\n          bgp-vpn:\n            bgp-instance:\n            - id: 1\n              route-target:\n                export-rt: target:65535:100\n                import-rt: target:65535:100\n        type: mac-vrf\n        vxlan-interface:\n        - name: vxlan0.100\n      tunnel-interface:\n      - name: vxlan0\n        vxlan-interface:\n        - index: 100\n          ingress:\n            vni: 100\n          type: bridged\n  lifecycle: {}\n  priority: 10\nstatus: {}\n\n    out/config.sdcio.dev_v1alpha1.Config.default.topo3nodesrl.vpc100.edge02.yaml:  apiVersion: config.sdcio.dev/v1alpha1\nkind: Config\nmetadata:\n  creationTimestamp: null\n  labels:\n    config.sdcio.dev/targetName: edge02\n    config.sdcio.dev/targetNamespace: default\n  name: topo3nodesrl.vpc100.edge02\n  namespace: default\nspec:\n  config:\n  - path: /\n    value:\n      interface:\n      - admin-state: enable\n        description: k8s-ethernet-1/1\n        ethernet: {}\n        name: ethernet-1/1\n        subinterface:\n        - admin-state: enable\n          description: k8s-customer\n          index: 100\n          type: bridged\n          vlan:\n            encap:\n              single-tagged:\n                vlan-id: 100\n        vlan-tagging: true\n      network-instance:\n      - admin-state: enable\n        description: k8s-vpc100.br100\n        interface:\n        - name: ethernet-1/1.100\n        name: vpc100.br100\n        protocols:\n          bgp-evpn:\n            bgp-instance:\n            - admin-state: enable\n              encapsulation-type: vxlan\n              evi: 100\n              id: 1\n              vxlan-interface: vxlan0.100\n          bgp-vpn:\n            bgp-instance:\n            - id: 1\n              route-target:\n                export-rt: target:65535:100\n                import-rt: target:65535:100\n        type: mac-vrf\n        vxlan-interface:\n        - name: vxlan0.100\n      tunnel-interface:\n      - name: vxlan0\n        vxlan-interface:\n        - index: 100\n          ingress:\n            vni: 100\n          type: bridged\n  lifecycle: {}\n  priority: 10\nstatus: {}\n\nStatus:\nEvents:  &lt;none&gt;\n</code></pre> <p>Awesome, we hope you enjoyed and thanks for completing these exercises. If you have other ideas, suggestion or want to discuss this further join us here</p>"},{"location":"03-community/01_about/","title":"Community","text":"<p>Join us on this journey as we learn how to leverage kubernetes for network automation.</p> <p>Have questions, ideas, bug reports or just want to chat? Come join our discord server.</p>"}]}